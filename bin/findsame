#!/usr/bin/env python3

import argparse
import json
from multiprocessing import cpu_count

from findsame import common as co
from findsame import main, calc
from findsame.config import cfg


if __name__ == '__main__':

    desc = "Find same files and dirs based on file hashes."
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument("files_dirs", nargs="+", metavar="file/dir",
                        help="files and/or dirs to compare", default=[])
    parser.add_argument("-b", "--blocksize",
                        default=co.size2str(cfg.blocksize),
                        help="blocksize in hash calculation, "
                             "use units K,M,G as in 100M, 218K or just "
                             "1024 (bytes) "
                             "[default: %(default)s]")
    parser.add_argument("-l", "--limit",
                        default=co.size2str(cfg.limit),
                        help="read limit (bytes or 'auto'), if bytes then "
                             "same units as for BLOCKSIZE apply, "
                             "calculate hash only over the first LIMIT "
                             "bytes, makes things go faster for may large "
                             "files, try 500K [default: %(default)s], use "
                             "'auto' to try to determine the smallest value "
                             "necessary automatically")
    parser.add_argument("-L", "--auto-limit-min",
                        default=co.size2str(cfg.auto_limit_min),
                        help="start value for auto LIMIT optimization when "
                             "--limit auto is used [default: %(default)s]")
    parser.add_argument("-c", "--auto-limit-converged",
                        default=cfg.auto_limit_converged, type=int,
                        help="how many times we find the same number of equal "
                             "files in a row to consider auto limit converged "
                             "[default: %(default)s]")
    parser.add_argument("-p", "--nprocs",
                        default=cfg.nprocs, type=int,
                        help="number of parallel processes [default: %(default)s]")
    parser.add_argument("-t", "--nthreads",
                        default=cpu_count(), type=int,
                        help="threads per process [default: %(default)s]")
    parser.add_argument("-o", "--outmode",
                        default=cfg.outmode, type=int,
                        help="1: list of dicts (values of dict from mode 2), one "
                             "dict per hash, 2: dict of dicts (full result), "
                             "keys are hashes, 3: compact, sort by type "
                             "(file, dir) [default: %(default)s]")
    parser.add_argument("-v", "--verbose",
                        default=cfg.verbose, action="store_true",
                        help="enable verbose/debugging output")
    args = parser.parse_args()

    cfg.nprocs = args.nprocs
    cfg.nthreads = args.nthreads
    cfg.blocksize = co.str2size(args.blocksize)
    cfg.limit = args.limit if args.limit == 'auto' else co.str2size(args.limit)
    cfg.auto_limit_min = co.str2size(args.auto_limit_min)
    cfg.auto_limit_converged = args.auto_limit_converged
    cfg.verbose = args.verbose
    cfg.outmode = args.outmode

    print(json.dumps(main.main(files_dirs=args.files_dirs)))
