#!/usr/bin/env python3

import argparse, json
from multiprocessing import cpu_count
from findsame import common as co
from findsame import main
from findsame.config import config

if __name__ == '__main__':

    desc = "Find same files and dirs based on file hashes."
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('files_dirs', nargs='+', metavar='file/dir',
                        help='files and/or dirs to compare', default=[])
    parser.add_argument('-b', '--blocksize', 
                        default=co.size2str(config.blocksize),
                        help='read-in blocksize in hash calculation, '
                             'use units K,M,G as in 100M, 218K or just '
                             '1024 (bytes) '
                             '[%(default)s]')
    parser.add_argument('-l', '--limit', 
                        default=co.size2str(config.limit),
                        help='read limit (bytes), same units as BLOCKSIZE, '
                             'calculate hash only for the first LIMIT '
                             'bytes, makes things go faster for may large files '
                             '[%(default)s]')
    parser.add_argument('-p', '--nprocs', 
                        default=1, type=int,
                        help='number of parallel processes [%(default)s]')
    parser.add_argument('-t', '--nthreads', 
                        default=cpu_count(), type=int,
                        help='threads per process [%(default)s]')
    parser.add_argument('-v', '--verbose', 
                        default=False, action='store_true',
                        help='output actual hashes as well')
    args = parser.parse_args()

    config.nprocs = args.nprocs
    config.nthreads = args.nthreads
    config.blocksize = co.str2size(args.blocksize)
    config.limit = co.str2size(args.limit)
    config.verbose = args.verbose
    print(json.dumps(main.main(files_dirs=args.files_dirs, config=config)))
